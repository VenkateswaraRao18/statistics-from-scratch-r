# Chapter 3: Descriptive Statistics

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE
)
```

Descriptive statistics answers the question:

"What does our data look like?"

Before building models, we must understand the structure of data.

---

## Create Sample Data

To make this chapter self-contained, we define data here.

```{r}
sales <- c(120, 135, 150, 98, 175, 142)
category <- c("Electronics", "Clothing", "Electronics", 
              "Groceries", "Clothing", "Electronics")
```

---

## What Is Descriptive Statistics?

Descriptive statistics summarizes and visualizes data.

It does NOT make predictions about populations.

It answers:

- What is the average?
- How spread out is the data?
- What values occur most often?
- What does the distribution look like?

---

# Measures of Central Tendency

## Mean (Average)

\[
\bar{x} = \frac{\sum x_i}{n}
\]

```{r}
mean(sales)
```

The mean is the balance point of data.

---

## Median

```{r}
median(sales)
```

Median is resistant to outliers.

```{r}
sales_with_outlier <- c(sales, 1000)
mean(sales_with_outlier)
median(sales_with_outlier)
```

Notice how the mean changes dramatically, but the median does not.

---

## Mode

```{r}
table(category)
```

Mode is the most frequent value.

For categorical data, mode is extremely useful.

---

# Comparing Mean and Median

- Mean ≈ Median → symmetric data
- Mean > Median → right skew
- Mean < Median → left skew

---

# Measures of Dispersion

Central tendency shows center.
Dispersion shows variability.

---

## Range

```{r}
range(sales)
diff(range(sales))
```

Range depends only on extreme values.

---

## Variance

\[
s^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}
\]

```{r}
var(sales)
```

Variance measures average squared deviation.

---

## Standard Deviation

\[
s = \sqrt{s^2}
\]

```{r}
sd(sales)
```

Low SD → stable data  
High SD → volatile data  

---

## Coefficient of Variation

\[
CV = \frac{s}{\bar{x}}
\]

```{r}
sd(sales) / mean(sales)
```

Used for comparing variability across scales.

---

# Frequency Distribution

## Categorical

```{r}
table(category)
```

## Numerical (Histogram)

```{r, fig.width=6, fig.height=4}
hist(sales, 
     col="lightblue", 
     main="Sales Distribution",
     xlab="Sales",
     ylab="Frequency")
```

---

# Bar Chart

```{r, fig.width=6, fig.height=4}
barplot(table(category),
        col="steelblue",
        main="Category Distribution")
```

---

# Boxplot

```{r, fig.width=6, fig.height=4}
boxplot(sales,
        col="orange",
        main="Sales Boxplot")
```

Boxplot shows:

- Median
- Quartiles
- Outliers

---

# Shape of Distribution

Distribution shape matters.

## Simulate Right Skew

```{r, fig.width=6, fig.height=4}
set.seed(123)
right_skew <- rexp(1000)
hist(right_skew, col="red", main="Right Skewed Distribution")
```

---

## Simulate Normal Distribution

```{r, fig.width=6, fig.height=4}
normal_data <- rnorm(1000)
hist(normal_data, col="green", main="Normal Distribution")
```

Understanding shape helps in:

- Feature transformation
- Log scaling
- Model assumptions

---

# Business Interpretation

Company A:
Mean = 1M  
SD = 50K  

Company B:
Mean = 1M  
SD = 500K  

Both have same mean.
But B is riskier.

Descriptive statistics reveals risk.

---

# Descriptive Statistics in Machine Learning

Before training models:

- Check distribution
- Detect outliers
- Standardize features
- Identify skewness

## Standardization

```{r}
scaled_sales <- scale(sales)
scaled_sales
```

Standardization ensures:

Mean = 0  
Standard deviation = 1  

Critical for:

- Logistic Regression
- SVM
- Neural Networks
- K-means

---

# Summary

In this chapter we learned:

- Mean, Median, Mode
- Range, Variance, Standard Deviation
- Coefficient of Variation
- Histograms, Barplots, Boxplots
- Distribution shapes
- Business interpretation
- Machine learning relevance

Descriptive statistics is the foundation of data understanding.